{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bda_mid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZaOkGQ2vF82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTYpCMfKAiNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0BsMKD_A73p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/ntu_bda/bda2020_dataset\")\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yWE2RQy6KRw",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 & 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15X-4kCOGNF9",
        "colab_type": "text"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhlei_tHCDoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"keyword.csv\", encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaOWyj_7XjBj",
        "colab_type": "code",
        "outputId": "f9bdcb79-7bd7-464d-aeb6-f705bf74da0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7198, 202)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0WI2PD4_p9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ryZDxXaFeEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,1:-1]\n",
        "y = df['up'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i_Db1ldWWO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# formatting the column names\n",
        "keyword_list = X.columns\n",
        "X.columns = ['x'+str(i) for i in range(1, X.shape[1]+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYSsPsMmjiXT",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the correlation between the keywords to further tweak vectorization methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwGyGQLpsOZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2vPmZrorFV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(13,10))\n",
        "sns.heatmap(X.corr(), cmap=sns.cm.rocket_r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQh3ecgzCk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating the most occuring keywords\n",
        "top_keywords = X.sum().sort_values(ascending=False).head(20).index.tolist()\n",
        "top_keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p339bwLx_ct",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLhPVG7Fi1cH",
        "colab_type": "text"
      },
      "source": [
        "Standardizing the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6DUbllaFK9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxE28UTf-u6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEISXnwsba_w",
        "colab_type": "code",
        "outputId": "601f3378-aa91-4c8c-9ab1-a6f5861d0047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(scaled_X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70592, 200)\n",
            "(70592,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXBfd4Tcite7",
        "colab_type": "text"
      },
      "source": [
        "Testing PCA's viability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ake9gkpSW5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA().fit(scaled_X_train)\n",
        "np.cumsum(pca.explained_variance_ratio_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXAHQl4aYdps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=60)\n",
        "pca_scaled_X_train = pca.fit_transform(scaled_X_train)\n",
        "pca_scaled_X_test = pca.fit_transform(scaled_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ard2dIxmiFip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pca_scaled_X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9ZPgm-OCuBl",
        "colab_type": "text"
      },
      "source": [
        "### Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUCLGokuA9fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the modules\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVd1loLS9G7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba_5U2vC99Ik",
        "colab_type": "text"
      },
      "source": [
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyX9ka6i-ALm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_param = {'alpha': np.arange(0, 0.51, 0.01)}\n",
        "\n",
        "nb = BernoulliNB()\n",
        "nb_cv = GridSearchCV(nb, nb_param, cv=4, refit=True, verbose=3) \n",
        "nb_cv.fit(scaled_X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0yxsqvU-XXm",
        "colab_type": "code",
        "outputId": "ab20821d-5c4f-4874-bdb6-274b130109af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(nb_cv.best_score_)\n",
        "print(nb_cv.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7325468351864721\n",
            "{'alpha': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz2y9e8uF_YI",
        "colab_type": "text"
      },
      "source": [
        "#### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkEnGap-D-gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = []\n",
        "\n",
        "for i in range(3,10):\n",
        "    knn = KNeighborsClassifier(n_neighbors = i)\n",
        "    score = cross_val_score(knn, scaled_X_train, y_train, cv=4, verbose=3).mean()\n",
        "    scores.append(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDwFXdWnCO-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(3,10), scores, '-o')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bB6lzxPJPSg",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peO2G7deJWzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_param = {'max_depth': np.arange(2, 11),\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'n_estimators': np.arange(50, 201, 50)}\n",
        "\n",
        "param = {'alpha':np.arange(0,1,0.1)}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_cv = GridSearchCV(rf, rf_param, cv=4, refit=True, verbose=3) \n",
        "rf_cv.fit(scaled_X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEtNFrIDX4R1",
        "colab_type": "code",
        "outputId": "d7a56d92-c01b-4fe2-80c5-3450220ea96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(rf_cv.best_score_)\n",
        "print(rf_cv.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7375824019380742\n",
            "{'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvsDpCNqJXOk",
        "colab_type": "text"
      },
      "source": [
        "#### SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IxzExT1Jaz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_param = {'C': [0.1, 1, 10, 100, 1000],  \n",
        "             'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "             'kernel': ['rbf']}\n",
        "\n",
        "svm = SVC()\n",
        "svm_cv = GridSearchCV(svm, svm_param, cv=2, refit=True, verbose=3) \n",
        "svm_cv.fit(scaled_X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_bpZga6WfZf",
        "colab_type": "code",
        "outputId": "b8aaa06a-ee65-4e4c-e640-90d7717d2f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(svm_cv.best_score_)\n",
        "print(svm_cv.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.738971865230983\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH92aLxhLhRS",
        "colab_type": "text"
      },
      "source": [
        "#### DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCJe9joYL8Vt",
        "colab_type": "code",
        "outputId": "3ca90760-85ad-44a8-e7c0-ea7f2d0e4285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import losses\n",
        "from keras import optimizers\n",
        "from keras import metrics\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation=\"relu\", input_shape=(scaled_X_train.shape[1],)))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(16, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    \n",
        "    # assigning optimizer, loss function, and evaluation metric\n",
        "    model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "                  loss=losses.binary_crossentropy,\n",
        "                  metrics=[metrics.binary_accuracy]) # using custom MCC metric to calculate accuracy\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21ZXshhzZf3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# hyperparameters\n",
        "epochs = 100\n",
        "batch_size = 1000\n",
        "\n",
        "# splitting the data into 4 folds for cross validation \n",
        "kfold = StratifiedKFold(n_splits=4)\n",
        "all_history = []\n",
        "\n",
        "# fitting model & cross validation\n",
        "for index, (train, val) in enumerate(kfold.split(scaled_X_train, y_train)):\n",
        "    print(\"Fold #\", index+1)\n",
        "    model = build_model()\n",
        "    history = model.fit(scaled_X_train[train],\n",
        "                        y_train[train],\n",
        "                        validation_data=(scaled_X_train[val], y_train[val]),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=1)\n",
        "    acc_history = history.history['val_binary_accuracy']\n",
        "    all_history.append(acc_history)\n",
        "\n",
        "print(all_history)\n",
        "\n",
        "# used to optimize number of epochs\n",
        "average_acc_history = [np.mean([x[i] for x in all_history]) for i in range(epochs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzpEiBSMaKT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(1, len(average_acc_history) + 1), average_acc_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKzX6eugad-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "model.fit(scaled_X_train,\n",
        "          y_train,\n",
        "          epochs=10,\n",
        "          batch_size=1000,\n",
        "          verbose=1,\n",
        "          class_weight=class_weights)\n",
        "\n",
        "y_prob = model.predict(scaled_X_test)\n",
        "y_pred = np.where(y_prob>0.5, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-fscgW5eE0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8eZCtbCuJA",
        "colab_type": "text"
      },
      "source": [
        "#### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvD_8WyoDJm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gb_param = {\n",
        "    \"learning_rate\": [0.0001, 0.001, 0.01],\n",
        "    'max_depth': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    \"n_estimators\":[10]\n",
        "    }\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb_cv = GridSearchCV(gb, gb_param, cv=4, refit=True, verbose=3) \n",
        "gb_cv.fit(scaled_X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KopijIM5E7U4",
        "colab_type": "code",
        "outputId": "fc54c75e-68e5-4d78-8102-708f4d00236a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(gb_cv.best_score_)\n",
        "print(gb_cv.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6932963670759014\n",
            "{'learning_rate': 0.0001, 'max_depth': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad1wIMt6YJFg",
        "colab_type": "text"
      },
      "source": [
        "### Comparing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdwf3itPGW5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [KNeighborsClassifier(n_neighbors=6),\n",
        "               BernoulliNB(alpha=0.1),\n",
        "               SVC(kernel=\"rbf\", C=1000, gamma=0.0001),\n",
        "               DecisionTreeClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2),\n",
        "               RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100),\n",
        "               GradientBoostingClassifier(learning_rate=0.0001, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqtZD92JGjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = []\n",
        "pre = []\n",
        "rec = []\n",
        "f1 = []\n",
        "\n",
        "for classifier in classifiers:\n",
        "  classifier.fit(scaled_X_train, y_train)\n",
        "  y_pred = classifier.predict(scaled_X_test)\n",
        "  acc.append(accuracy_score(y_test, y_pred))\n",
        "  pre.append(precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
        "  rec.append(recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
        "  f1.append(f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnCcswfXyWqf",
        "colab_type": "text"
      },
      "source": [
        "#### Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AN0H-OhZDnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [('knn', KNeighborsClassifier(n_neighbors=6)),\n",
        "              ('nb', BernoulliNB(alpha=0.1)),\n",
        "              ('svm', SVC(kernel=\"rbf\", C=1000, gamma=0.0001)),\n",
        "              ('dt', DecisionTreeClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2)),\n",
        "              ('rf', RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100)),\n",
        "              ('gb', GradientBoostingClassifier(learning_rate=0.0001, max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=10))]\n",
        "\n",
        "voting = VotingClassifier(estimators=estimators, voting = 'hard')\n",
        "voting.fit(scaled_X_train,y_train)\n",
        "y_pred = voting.predict(scaled_X_test)\n",
        "acc.append(accuracy_score(y_test, y_pred))\n",
        "pre.append(precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
        "rec.append(recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
        "f1.append(f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7SupncEycbd",
        "colab_type": "text"
      },
      "source": [
        "#### DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XOKTDRqqhheJ",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "model.fit(scaled_X_train,\n",
        "          y_train,\n",
        "          epochs=10,\n",
        "          batch_size=1000,\n",
        "          verbose=1)\n",
        "\n",
        "y_prob = model.predict(scaled_X_test)\n",
        "y_pred = np.where(y_prob>0.5, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_JyHHpsYhhed",
        "colab": {}
      },
      "source": [
        "acc.append(accuracy_score(y_test, y_pred))\n",
        "pre.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "rec.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "f1.append(f1_score(y_test, y_pred, average='weighted'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n4fuPhqyixG",
        "colab_type": "text"
      },
      "source": [
        "#### Full Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BgvfqqjJuM_",
        "colab_type": "code",
        "outputId": "2a9b36d2-ad53-48ae-f6be-d55c9ec62a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "models = pd.DataFrame({'Model': ['KNN','Naive Bayes','SVM','Decision Tree','Random Forest',\n",
        "                                 'Gradient Boosting','Voting Classifier','DNN'],\n",
        "                       'Accuracy':acc,\n",
        "                       'Precision':pre,\n",
        "                       'Recall':rec,\n",
        "                       'F1':f1})\n",
        "\n",
        "models.sort_values(by='F1', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.703472</td>\n",
              "      <td>0.703472</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.825927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.736111</td>\n",
              "      <td>0.718544</td>\n",
              "      <td>0.736111</td>\n",
              "      <td>0.689497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.753603</td>\n",
              "      <td>0.743750</td>\n",
              "      <td>0.682746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>DNN</td>\n",
              "      <td>0.726389</td>\n",
              "      <td>0.700736</td>\n",
              "      <td>0.726389</td>\n",
              "      <td>0.679805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Voting Classifier</td>\n",
              "      <td>0.740972</td>\n",
              "      <td>0.748056</td>\n",
              "      <td>0.740972</td>\n",
              "      <td>0.678608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.747280</td>\n",
              "      <td>0.739583</td>\n",
              "      <td>0.675462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.723142</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.673694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.717361</td>\n",
              "      <td>0.685090</td>\n",
              "      <td>0.717361</td>\n",
              "      <td>0.670126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model  Accuracy  Precision    Recall        F1\n",
              "5  Gradient Boosting  0.703472   0.703472  1.000000  0.825927\n",
              "2                SVM  0.736111   0.718544  0.736111  0.689497\n",
              "4      Random Forest  0.743750   0.753603  0.743750  0.682746\n",
              "7                DNN  0.726389   0.700736  0.726389  0.679805\n",
              "6  Voting Classifier  0.740972   0.748056  0.740972  0.678608\n",
              "1        Naive Bayes  0.739583   0.747280  0.739583  0.675462\n",
              "3      Decision Tree  0.733333   0.723142  0.733333  0.673694\n",
              "0                KNN  0.717361   0.685090  0.717361  0.670126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LBk93-e5Ykr",
        "colab_type": "text"
      },
      "source": [
        "## Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyguORn46XQ1",
        "colab_type": "text"
      },
      "source": [
        "### Loading & Processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaVuTaW6mxEw",
        "colab_type": "text"
      },
      "source": [
        "Predetermining the keywords of our interest, i.e., the variables for our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc8flqr3nqrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keyword = pd.read_csv('keyword.csv', encoding='utf-8').iloc[:,1:-1].columns.tolist() # count_matrix_0001_y9bbs5.csv\n",
        "news = pd.read_csv('news.csv', encoding='utf-8')\n",
        "news.post_time = pd.to_datetime(news.post_time).dt.date\n",
        "news['all_content'] = news['title'] + news['content'] # concatenating title and content "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h1odOTlpKPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(keyword)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wjzwT8cMb55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "from dateutil.relativedelta import relativedelta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McFF0anFmOaG",
        "colab_type": "text"
      },
      "source": [
        "Determining whether the stock price of D+5 increased or decreased (using an absolute value of 0.3% growth)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2_DMrvhcO7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stock_data_2016 = pd.read_csv(\"stock_data_2016.csv\", usecols=(0,1,5), thousands=',')\n",
        "stock_data_2017 = pd.read_csv(\"stock_data_2017.csv\", usecols=(0,1,5), thousands=',')\n",
        "stock_data_2018 = pd.read_csv(\"stock_data_2018.csv\", usecols=(0,1,5), thousands=',')\n",
        "stock_data = pd.concat([stock_data_2016, stock_data_2017, stock_data_2018])\n",
        "y9999 = stock_data.loc[stock_data['證券代碼'] == 'Y9999 加權指數'].drop(columns='證券代碼')\n",
        "y9999.columns = ['time','price']\n",
        "y9999.time = pd.to_datetime(y9999.time).dt.date"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32m8EXfPoZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y9999.sort_values(by = 'time', inplace = True)\n",
        "y9999.reset_index(drop = True, inplace = True)\n",
        "y9999['diff'] = y9999.price.pct_change()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oeT-Xmif6ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y9999.loc[y9999['diff'].shift(-5)>0.003, \"up\"] = 1 # determining movement based on the daily stock return of D+5\n",
        "y9999.loc[y9999['diff'].shift(-5)<-0.003, \"up\"] = 0\n",
        "y9999.fillna(-1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkUifkDb7sPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = y9999[['time', 'up']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF76KsUQlkOK",
        "colab_type": "text"
      },
      "source": [
        "Determining dates with number of posts higher than the 3rd quartile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDM4BV9wkSbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forum = pd.read_csv('forum.csv')\n",
        "bbs = pd.read_csv('bbs.csv')\n",
        "discuss = forum.append(bbs)\n",
        "discuss.post_time = discuss.post_time.astype('datetime64[ns]').apply(lambda x: x.date())\n",
        "n_discuss = discuss.groupby('post_time').count().sort_values('id', ascending=False)\n",
        "dates = n_discuss[n_discuss.id>np.percentile(n_discuss.id, 75)]\n",
        "date_list = dates.index.tolist() # list of dates with high volume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvREW5976eAO",
        "colab_type": "text"
      },
      "source": [
        "### Functions & Modeling Preps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVfM_s9HqKS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obtaining each keyword's occurences in each piece of news\n",
        "def get_keyword_ct(news_qt):\n",
        "  ct_dicts = []\n",
        "  for i in range(0, len(news_qt)):\n",
        "    ct_dict = {}\n",
        "    for key in keyword:\n",
        "      try:\n",
        "        # count number of occurences in \"all_content\"\n",
        "        key_ct = news_qt.iloc[i].all_content.count(key) \n",
        "      except AttributeError:\n",
        "        key_ct = 0\n",
        "      ct_dict[key] = key_ct\n",
        "    ct_dicts.append(ct_dict)\n",
        "  df = pd.DataFrame(ct_dicts)\n",
        "  df.index = news_qt.id\n",
        "  df.insert(0, \"post_time\", news_qt.post_time.values)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKVbGQboy_H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keeping 0s and 1s, producing final confusion matrix\n",
        "def get_results(y_ans, predictions):\n",
        "  y_ans_keep = [i for i, x in enumerate(y_ans) if x==0 or x==1] \n",
        "  predictions_keep = [i for i, x in enumerate(predictions) if x==0 or x==1]\n",
        "  keep = set(y_ans_keep).intersection(predictions_keep) # list of indices with 0s and 1s in both the answer list and the prediction list\n",
        "  predictions_final = [predictions[i] for i in keep]\n",
        "  y_ans_final = [y_ans[i] for i in keep]\n",
        "  CM = confusion_matrix(y_ans_final, predictions_final)\n",
        "  return CM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr2IpgBxP4r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determining voting classifier estimators (SVM & RF)\n",
        "# hyperparameters predetermined using GridSearchCV\n",
        "estimators = [('svm', SVC(kernel=\"rbf\", C=10, gamma=0.001,\n",
        "                          class_weight=\"balanced\")),\n",
        "              ('rf', RandomForestClassifier(max_depth=9, min_samples_leaf=2, \n",
        "                                      min_samples_split=5, n_estimators=200,\n",
        "                                      class_weight=\"balanced\"))]\n",
        "\n",
        "                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSp_4PwNhq8c",
        "colab_type": "text"
      },
      "source": [
        "### Modeling & Final Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0XiNUarKoNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TN = 0 # true negatives (correct sell prediction)\n",
        "FN = 0 # false negatives (wrong sell prediction)\n",
        "TP = 0 # true positives (correct buy prediction)\n",
        "FP = 0 # false positives (wrong buy prediction)\n",
        "\n",
        "for i in range(33): # split into 33 sets / months\n",
        "  print('Processing Month #%d' % (i+1))\n",
        "  start_date = datetime.strptime('2016-01-01', '%Y-%m-%d').date() + relativedelta(months=i)\n",
        "  end_date = start_date + relativedelta(months=4)\n",
        "  test_month = end_date - relativedelta(months=1)\n",
        "  news_qt = news[(news.post_time >= start_date) & (news.post_time < end_date)] # df of news in our training / testing sets\n",
        "  news_price = get_keyword_ct(news_qt).merge(y9999[['time', 'up']], how='left', left_on='post_time', right_on='time').drop(columns='time')\n",
        "  test_all = news_price[news_price.post_time >= test_month] # leaving out the last month as testing sets\n",
        "  train = news_price[(news_price.up.isin([0,1])) & (news_price.post_time.isin(date_list)) & (news_price.post_time < test_month)]\n",
        "  X_train = train.iloc[:,1:-1]\n",
        "  y_train = train['up'].values\n",
        "  try:\n",
        "    scaled_X_train = scaler.fit_transform(X_train)\n",
        "  except ValueError:\n",
        "    continue\n",
        "  # fit voting classifier\n",
        "  voting = VotingClassifier(estimators=estimators, voting = 'hard')\n",
        "  try:\n",
        "    voting.fit(scaled_X_train,y_train)\n",
        "  except ValueError:\n",
        "    continue\n",
        "  \n",
        "  predictions = []\n",
        "  ans_time = ans.loc[(ans.time>=test_month) & (ans.time<end_date), 'time']\n",
        "  # predict with testing sets (for each day in month) \n",
        "  for date in ans_time:\n",
        "    test = test_all[test_all.post_time==date]\n",
        "    X_test = test.iloc[:,1:-1]\n",
        "    try:\n",
        "      scaled_X_test = scaler.fit_transform(X_test)\n",
        "    except ValueError:\n",
        "      continue\n",
        "    y_pred = voting.predict(scaled_X_test)\n",
        "\n",
        "    # if (number of 1 predictions/number of 0 predictions) -1 >= 0.2, return 1; if <= -0.2, return 0; otherwise, -1\n",
        "    try:\n",
        "      y_pred_prob = np.count_nonzero(y_pred==1)/np.count_nonzero(y_pred==0)-1\n",
        "    except ZeroDivisionError:\n",
        "      y_pred_prob = 1\n",
        "    if y_pred_prob >= 0.2:\n",
        "      predictions.append(1)\n",
        "    elif y_pred_prob <= -0.2:\n",
        "      predictions.append(0)\n",
        "    else:\n",
        "      predictions.append(-1)\n",
        "\n",
        "  y_ans = ans.loc[(ans.time>=test_month) & (ans.time<end_date), 'up'].tolist() # true stock movements\n",
        "\n",
        "  # tally final results\n",
        "  try:\n",
        "    CM = get_results(y_ans, predictions)\n",
        "  except IndexError:\n",
        "    continue\n",
        "\n",
        "  TN += CM[0][0] \n",
        "  FN += CM[1][0] \n",
        "  TP += CM[1][1] \n",
        "  FP += CM[0][1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LwEw0YVkd3n",
        "colab_type": "text"
      },
      "source": [
        "At long last, the final results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It0zzRPNbaMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_results = pd.DataFrame([[TP,FP],[FN,TN]], columns=['真實為漲','真實為跌'], index=['預測為漲','預測為跌'])\n",
        "final_results.to_csv('final_results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vLwibx1fGPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_results"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}